# -*- coding: utf-8 -*-
"""DAG_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AG752sksil_cwDmWYIvj1czGImPfXWdW
"""

#pip install apache-airflow

from datetime import date
import datetime
import pandas as pd

from airflow import DAG
from airflow.operators.bash import BashOperator

# Importar PythonOperator arriba del archivo
from airflow.operators.python import PythonOperator

import psycopg2
import csv
import boto3

s3 = boto3.resource(
    service_name="s3",
    aws_access_key_id = "AKIA4PFNY54U34VBUBRF",
    aws_secret_access_key = "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"
    )


def FiltrarDatos():
  hoy = date.today().strftime('%Y-%m-%d')
  url1= s3.Bucket('data-recomendaciones').Object('advertiser_ids.csv').get()
  url2= s3.Bucket('data-recomendaciones').Object('ads_views.csv').get()
  url3= s3.Bucket('data-recomendaciones').Object('product_views.csv').get()
    
  #url1='/home/ubuntu/grupo-kvd/advertiser_ids.csv'
  adv_ids = pd.read_csv(url1['Body'], index_col=0)
  
  #url2='/home/ubuntu/grupo-kvd/ads_views.csv'
  ads_views = pd.read_csv(url2['Body'])

  #url3='/home/ubuntu/grupo-kvd/product_views.csv'
  product_views = pd.read_csv(url3['Body'])

  #Listado de views de advertisers activos
  ads_views_today = ads_views[ads_views['date'] == hoy]
  ads_views_activos = pd.merge(ads_views_today, adv_ids, on = 'advertiser_id', how = 'inner')

  #Log de vistas de productos en la pÃ¡gina del cliente
  product_views_today = product_views[product_views['date'] == hoy]
  product_views_activos = pd.merge(product_views_today, adv_ids, on = 'advertiser_id', how = 'inner')
  product_views_activos.to_csv("product_views_activos.csv")
  s3.Bucket("data-recomendaciones").upload_file(Filename="product_views_activos.csv",Key="product_views_activos.csv")

def TopProduct ():
  prod_views_activos = s3.Bucket('data-recomendaciones').Object('product_views_activos.csv').get()
  product_views_activos = pd.read_csv(prod_views_activos['Body'], index_col=0)
  TopProduct_final=product_views_activos['Body'].groupby(["advertiser_id","date",'product_id'], as_index=False).count()
  TopProduct_final.columns = [ 'advertiser_id', 'date', 'product_id','count']
  TopProduct_final=TopProduct_final.sort_values(by = ["advertiser_id",'count'], ascending = False)
  TopProduct_final=TopProduct_final.groupby(["advertiser_id"]).head(20)
  TopProduct_final['Model'] = 'TopProduct'
  

#def TopCTR(ads_views_activos):
#  #ads_views_activos = pd.read_csv(df_ads_view)
#  ads_views_activos['flag'] = 1
#  ads_views_activos_pivot = pd.pivot_table(ads_views_activos, index=['advertiser_id','product_id', 'date'], columns = ['type'], values = ['flag'], aggfunc = {'flag' : 'sum'}).reset_index()
#  ads_views_activos_pivot['rate'] = ads_views_activos_pivot['flag']['click'].fillna(0)/ads_views_activos_pivot['flag']['impression']
#  TopCTR_final = ads_views_activos_pivot.sort_values(by = 'rate', ascending = False)
#  TopCTR_final.columns = [ 'advertiser_id', 'product_id', 'date', 'click','impression','rate']
#  TopCTR_final = TopCTR_final.groupby(['advertiser_id']).head(20)
#  TopCTR_final['Model'] = 'TopCTR'
  

#from operator import concat
#engine = psycopg2.connect(
#      database="postgres",
#      user='postgres',
#      password='riverplate1995',
#      host="grupo-kvd.c7ezedheahhk.us-east-1.rds.amazonaws.com",
#      port='5432'
#  )

#def DBWriting(TopCTR_final,TopProduct_final):
#  #### Tabla TOPCTR ####
#  cursor = engine.cursor()
#  cursor.execute("""CREATE TABLE IF NOT EXISTS base_TopCTR_Final (advertiser_id VARCHAR,product_id VARCHAR, fecha_act DATE, click INT, impression INT, rate DECIMAL);""")
        
#  for i in range(0 ,len(TopCTR_final)):
#      values = (TopCTR_final['advertiser_id'][i],TopCTR_final['product_id'][i] , TopCTR_final['date'][i], TopCTR_final['click'][i], TopCTR_final['impression'][i], TopCTR_final['rate'][i])
#      cursor.execute("INSERT INTO base_TopCTR_Final (advertiser_id,product_id, fecha_act, click, impression, rate) VALUES (%s, %s, %s, %s, %s, %s)",
#                  values)

#  engine.commit()
#  #### Tabla TOPProduct ####
#  cursor = engine.cursor()
#  cursor.execute("""CREATE TABLE IF NOT EXISTS base_TopProduct_Final (advertiser_id VARCHAR, fecha_act DATE, product_id VARCHAR);""")
#        
#  for i in range(0 ,len(TopProduct_final)):
#      values = (TopProduct_final['advertiser_id'][i], TopProduct_final['date'][i], TopProduct_final['product_id'][i]  )
#      cursor.execute("INSERT INTO base_TopProduct_Final (advertiser_id, fecha_act, product_id) VALUES (%s, %s, %s)",
#                  values)

#  engine.commit()

with DAG(
    dag_id='Pipeline_TP_final',
    schedule_interval='@Daily',
    start_date=datetime.datetime(2022, 4, 1),
    catchup=False,
) as dag:

    FiltrarDatos = PythonOperator(
    task_id='FiltrarDatos',
    python_callable=FiltrarDatos
    )

     TopProduct = PythonOperator(
     task_id='TopProduct',
     python_callable=TopProduct()
     )

#     TopCTR = PythonOperator(
#     task_id='TopCTR',
#     python_callable=TopCTR()
#     )

#     DBWriting = PythonOperator(
#     task_id='DBWriting',
#     python_callable=DBWriting(TopCTR_final,TopProduct_final)
#     )

### dependencias

FiltrarDatos >> TopProduct
#FiltrarDatos >> TopCTR
#[TopCTR, TopProduct] >> DBWriting
